The function needs permission to call the Bedrock service as well. Finally, the function needs the polly:SynthesizeSpeech permission to access and use Amazon Polly service. As for the function’s code: import boto3 import json def lambda_handler(event, context): s3 boto3.client('s3') #Transcribe created json file location from the S3 event bucket event['Records'][0]['s3']['bucket']['name'] key event['Records'][0]['s3']['object']['key'] file s3.get_object(Bucketbucket, Keykey) content file['Body'].read().decode('utf-8') transcribed_text json.loads(content)['results']['transcripts'][0]['transcript'] bedrock_runtime boto3.client( service_name'bedrock-runtime', region_name'us-west-2' #the region where you have access to the model ) config { "modelId": "cohere.command-text-v14", #model id "contentType": "application/json", "accept": "/", "body": { "prompt": transcribed_text } } response bedrock_runtime.invoke_model( bodyjson.dumps(config['body']), modelIdconfig['modelId'], acceptconfig['accept'], contentTypeconfig['contentType'] ) #getting text response from model #this structure is specific to Cohere's Command llm_text json.loads(response.get('body').read())['generations'][0]['text'] #transforming the LLM's response to audio polly boto3.client('polly') response polly.synthesize_speech( Textllm_text, OutputFormat'mp3', VoiceId'Joanna' #can customize this, see AWS Documentation for voice IDs ) bucket_name 'audioResponsesBucket' key 'output.mp3' s3.put_object(Bucketbucket_name, Keykey, Bodyresponse['AudioStream'].read()) Copy This function retrieves the S3 object details (bucket and key) from the Lambda event object. Then, it reads the object and parses the transcription text from the object. The function then invokes the model available in Amazon Bedrock, passing it the user’s query transcribed. The response from the LLM is then transformed into speech using the Amazon Polly service which outputs the generated LLM text to MP3 format. Finally, the created audio file is uploaded to S3. At this point the audio output can be accessed from the bucket for further processing or sent back to the user using another Lambda function, depending on the application needs. Note: For the call to Bedrock, you can use whichever model suits your business needs, but make sure to include the correct request structure expected by each model according to the AWS Documentation. Moreover, for the bedrock-runtime service to be available in boto3, you must have an updated version of the boto3 package in your Lambda function’s environment. Finally, to parse the response from a different model and save it in the llm_text variable, refer to the documentation of the model to know the structure of the response returned by each model. Further Applications of Bedrock The out-of-the box models offered by Amazon Bedrock come with a variety of functionalities across natural language processing (NLP), text generation, and other creative applications. Incorporating these models into everyday business and creative workflows hints at infinite potential: Translation Services: They power real-time language translation for international communication and content localization.