Amazon’s Titan Embeddings model is specialized for this purpose and can generate the embeddings corresponding to your data. Once, the embeddings have been saved in a storage service such as S3, a lambda function can perform a similarity search using this vector database to retrieve only the data relevant to the user’s query. Next, this relevant data, also known as the context, is sent along with the user’s query to an LLM which will generate the appropriate response within the right context. Amazon’s Titan Text Express model is a suitable LLM for the job. Using Amazon Bedrock Knowledge bases , you can provide your model with context without having to add the extra step of performing the similarity search. Once your data is added as is as a Knowledge base to the model of your choice with the choice of a model to handle embeddings, the vector database is created on your behalf, and relevant information is automatically found based on the user query and combined with the query to generate an accurate response from the LLM basaed on the relevant context. Adding Speech to Text Layer To go the extra mile, you can use Amazon Transcribe to accept the user’s query in audio format and Amazon Polly to return the response to the user in audio Format. The architecture diagram below shows a high-level overview of the AWS services needed to create the well-rounded generative AI service to be integrated into existing business applications. Setting Up the Source S3 bucket The first step is uploading the user’s queries in a consistent audio format to an S3 bucket from the user’s device/application. For this S3 bucket, event notifications are needed to automatically trigger the audio transformation. For this, we can choose the option to create Event Notifications in the Properties section of a designated S3 bucket. We specify a suffix to match objects of a specific format to prevent mismatched formats during processing since we will need to declare this format later in the triggered transcription lambda function. For Event Types, we specify to match Put events according to the method used from the application to upload the audio file to the S3 bucket. As a destination of the event notification, we select the Lambda function and choose the created trigger Transcription function. This way, every time a new audio file is uploaded, it will be transcribed and sent to the LLM for a corresponding response. Trigger Transcription Lambda function Before diving into this function’s code, we need to enure that it has the appropriate permissions to function correctly. It will need a role assigned to it that contains the following permissions to programmatically start a transcription job using Amazon Transcribe and to delete the job once done to clean up resources. transcribe:StartTranscriptionJob transcribe:GetTranscriptionJob transcribe:DeleteTranscriptionJob It should also have permissions to read S3 objects and to write to the output bucket specified in the transcription job ( s3:GetObject and s3:PutObject permissions respectively). The function’s code can be found below. It first retrieves the Amazon S3 bucket name and object key from the Amazon S3 event notification that triggered its execution. Then, it creates and starts a transcription job that converts the audio from the Amazon S3 bucket into text saved in a json file along with metadata and confidence measures in the output bucket. When the transcription is over, the lambda function cleans up resources by deleting the transcription job based on its name and status of execution. import boto3 import time import uuid def lambda_handler(event, context): s3 boto3.client('s3') transcribe boto3.client('transcribe') #audio file location from the S3 event bucket event['Records'][0]['s3']['bucket']['name'] key event['Records'][0]['s3']['object']['key'] #output bucket to save transcriptions with same name but .json extension output_bucket 'textQueriesBucket' output_key key.split(".")[0] + '.json' job_name f"TranscriptionJob_{str(uuid.uuid4())}" #unique name for each invocation #starting transcription response transcribe.start_transcription_job( TranscriptionJobName job_name, LanguageCode'en-US', MediaFormat'mp3',   # audio format mentioned previously Media{ 'MediaFileUri': f's3://{bucket}/{key}' }, OutputBucketNameoutput_bucket, OutputKeyoutput_key ) #clean up resources while True: status transcribe.get_transcription_job(TranscriptionJobNamejob_name)['TranscriptionJob']['TranscriptionJobStatus'] if status not in ('QUEUED', 'IN_PROGRESS'): #completed, failed, or cancelled transcribe.delete_transcription_job(TranscriptionJobNamejob_name) break time.sleep(5) Copy Generate Text Lambda function The next step is to set up Event notifications on the textQueriesBucket to trigger the generateText Lambda function as done previously but without the suffix. This Lambda function has to be assigned a role that contains the permission policies to read data from the textQueriesBucket S3 bucket and put objects to the audioResponsesBucket S3 bucket ( s3:PutObject and s3:GetObject permissions).