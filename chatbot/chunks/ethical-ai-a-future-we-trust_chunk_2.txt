On the other hand, such technologies introduced new safety and ethical challenges; unintended deployments of code versions, safety hazards on civilians, and even a huge curve in the unemployment and laying off rates. One example of such hazards would be in 2018, an Uber autonomous vehicle tragically struck and took the life of a pedestrian in Arizona due to a failure in object recognitions. Investigators revealed that software limitations and the delay in braking configurations were key contributors in the incident as Uber prioritized “smooth driving” over pedestrian’s safety. Data Misuse: Data breaches and unconsented use of personal information are recurring events in the unethical world of AI. These breaches are used to exploit personal information to scam people, spread false information, and the list goes on and on. Scandals of such sorts happened in numerous of occasions and events, including the U.S. elections with the Cambridge Analytica Scandal. In 2016, Cambridge Analytica was involved in exploiting personal information from the social media platform Facebook, taking advantage of its, at the time, weak data privacy policies to target U.S. voters. During the 2016 presidential elections, about 87 million Facebook profiles were improperly accessed through an app created by the GSR (Global Science Research). The data was used to create psychographic profiles, deliver highly targeted advertisements, and promote voting campaigns.