Note that typical execution will not exceed 20 seconds. To do this, go to the ‘Configuration’ tab of the Lambda function, and click ‘Edit’ in the General Configuration section. AWS API Gateway APIs can be used to expose your Lambda function for use in applications, so that your Lambda function is triggered when this API is accessed by end-users. To create your own API, search for the API Gateway service in the AWS Management Console. Create a new API You will be redirected to a page with several options for the types of API, but for this tutorial we shall use REST APIs. Click ‘Build’. Choose REST and ‘New API’. Then, give your API a good name, and leave the endpoint type as ‘Regional’. Once the API is created, in the Resources section, click on ‘Create Resource’ in the Actions drop down menu. Name your child resource. From within the resource you have just created, click ‘Create Method’ in the Actions menu: Choose the type to be a POST method, as we will be sending data from the webpage in the body of the request. Once you confirm the type, this will redirect you to an editor to specify the details of your POST method. This includes the integration type, which should be set to Lambda so that your API can trigger your Lambda function’s execution. For the Lambda Function input field, enter the name of the Lambda function that you created in the previous section. Finally, save these options to create the POST method. In the Actions menu, click ‘Enable CORS’ to allow our webpage to access this API from its origin. The fields we will edit in this page are: Access-Control-Allow-Headers where we will add ‘Access-Control-Allow-Origin’ to the comma-separated list, and Access-Control-Allow-Origin where we will input ‘ https://localhost:3000 ’ in order to allow our webpage, running locally on port 3000 to call this API without errors. To ensure that this, setting has been set right, this will show in the Header Mappings section of the API’s Integration Response page (You can find this in the main page of your POST method): Finally, to make your API available for use, retrieve its corresponding URL, and make any updates available, you must deploy your API from the Actions drop-down menu. You will be prompted to select a Stage to keep track of your deployments, which you can customize and organize however you see fit. Once deployed, you will be able to access your URL for invoking your API in the Stages section of your API. For authentication purposes, you must create an API Key so that your API is available only to authorized users and applications,as this key allows use of this API. Go to API Keys, and click in Create API Key in the Actions menu. You can name your key and set it to either be auto generated by AWS or enter your own value. Once this key is saved, you will be able to use it from your API as shown in the React code previously. This will prevent the Authentication Token Missing error, which prevents you from using your API, even when using the Invoke URL. Note that every time you would like to apply new changes to the API, you must deploy the API again. SageMaker Configurations (Final Step): This article uses the same code and configuration as the first blog with minor changes to use Falcon-7B instead of Falcon 40B. In the serving.properties file, edit the tensor_parallel_degree option to be 1 in order to use a single GPU and the model_id option to use Falcon7B. %%writefile ./code_container/serving.properties enginePython option.model_id'tiiuae/falcon-7b' option.tensor_parallel_degree1 In the model.py file, edit the model name variable in the get_model method to be falcon-7b: model_name 'tiiuae/falcon-7b' In the endpoint configuration, change the instance type to ml.g5.2xlarge . endpoint_config_response maker.create_endpoint_config( EndpointConfigName'falcon7b-model-ds-cf', ProductionVariants[ { "VariantName": "falcon7", "ModelName": model_name, "InstanceType": 'ml.g5.2xlarge', "InitialInstanceCount": 1, "ModelDataDownloadTimeoutInSeconds": 1200, "ContainerStartupHealthCheckTimeoutInSeconds": 1200, }, ], ) You can change your model_name_acc , enpoint configuration name, and endpoint name to reflect using falcon7B instead of 40B. This change from falcon 40B to 7B is better to suit the relatively small workload of handling user input and more optimized with lower latency using one GPU. This is convenient for our real-time chat feature.